name: UCSP Algorithm - Weekly Data Scrape

# Trigger del workflow
on:
  # Ejecutar cada lunes a las 1 PM UTC (8 AM Per√∫)
  schedule:
    - cron: '0 13 * * 1'

  # Permitir ejecuci√≥n manual desde GitHub Actions UI
  workflow_dispatch:

jobs:
  scrape-and-commit:
    name: Scrape UCSP data from all sources (Apify)
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout del c√≥digo
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      # 2. Setup Node.js 20
      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'scrapers/package-lock.json'

      # 3. Instalar dependencias
      - name: Install dependencies
        working-directory: ./scrapers
        run: npm ci

      # 4. Crear directorios de datos
      - name: Create data directories
        run: |
          mkdir -p data/trends data/tiktok data/meta
          mkdir -p public/data/trends public/data/tiktok public/data/meta

      # 5. Ejecutar scraper de Google Trends (Apify)
      - name: Run Google Trends Scraper
        working-directory: ./scrapers
        run: |
          echo "üîç Scraping Google Trends via Apify..."
          node google_trends_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 6. Ejecutar scraper de TikTok (Apify)
      - name: Run TikTok Trends Scraper
        working-directory: ./scrapers
        run: |
          echo "üéµ Scraping TikTok Trends via Apify..."
          node tiktok_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 7. Ejecutar scraper de Meta/Facebook (Apify)
      - name: Run Meta/Facebook Scraper
        working-directory: ./scrapers
        run: |
          echo "üìò Scraping Facebook Pages via Apify..."
          node meta_apify.js --client=ucsp
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        continue-on-error: true

      # 8. Ejecutar ML Pipeline
      - name: Run ML Pipeline
        run: |
          echo "üß† Ejecutando ML Pipeline..."
          node ml/pipeline/weekly_pipeline.js
        continue-on-error: true

      # 9. Verificar archivos generados
      - name: Check generated files
        run: |
          echo "üìä Verificando archivos generados..."
          echo "=== Google Trends ===" && ls -lah data/trends/ || echo "No data"
          echo "=== TikTok ===" && ls -lah data/tiktok/ || echo "No data"
          echo "=== Meta ===" && ls -lah data/meta/ || echo "No data"
          echo "=== ML ===" && ls -lah public/data/ml/ || echo "No ML data"

      # 10. Commit y push de los datos
      - name: Commit and push data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "UCSP Algorithm Bot"

          git add data/ public/data/

          if git diff --staged --quiet; then
            echo "No hay cambios en los datos"
          else
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            git commit -m "üîÑ Update UCSP data + ML predictions - $TIMESTAMP"
            git push
            echo "‚úÖ Datos UCSP actualizados y pusheados"
          fi

      # 11. Notificaci√≥n
      - name: Status notification
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "‚úÖ UCSP Algorithm scraping completado"
            echo "üìÖ Pr√≥xima ejecuci√≥n: Pr√≥ximo lunes 8 AM (Per√∫)"
          else
            echo "‚ö†Ô∏è Algunos scrapers fallaron - revisa los logs"
          fi
